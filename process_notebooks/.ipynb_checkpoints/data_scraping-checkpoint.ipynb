{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Selenium WebDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first used Selenium to obtain all the links of the FOMC minutes on the FOMC website.\n",
    "\n",
    "Selenium offers an advantage over basic requests--it doesn't run into php/javacript tag selector issues because it simulates an actual human browsing the website. (The search engine from which the links are obtained uses a php/javascript backend.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize browser\n",
    "# Use Ctrl+Enter (don't use Shift+Enter)\n",
    "browser = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium allows us to go directly to the search page with text already in the input query. The following link is to the New York Federal Reserve's advanced search page that lists all available copies of online FOMC meeting minutes and statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "browser.get(\"http://search.newyorkfed.org/fomc-docs/search?advanced_search=true&fomc_document_type=minutes&text=.htm&search_precision=All+Words&from_month=3&from_year=1936&to_month=12&to_year=2015&sort=Most+Recent+First&Search=Search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through each page of the search results and collect all the links by storing them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of results\n",
      "=====================================\n",
      "Message: Unable to locate element: {\"method\":\"link text\",\"selector\":\"Next Page\"}\n",
      "Stacktrace:\n",
      "    at FirefoxDriver.prototype.findElementInternal_ (file:///var/folders/tq/rz1w3j390kqgxp1hc3mlhdc00000gn/T/tmplhSY8A/extensions/fxdriver@googlecode.com/components/driver-component.js:10659)\n",
      "    at FirefoxDriver.prototype.findElement (file:///var/folders/tq/rz1w3j390kqgxp1hc3mlhdc00000gn/T/tmplhSY8A/extensions/fxdriver@googlecode.com/components/driver-component.js:10668)\n",
      "    at DelayedCommand.prototype.executeInternal_/h (file:///var/folders/tq/rz1w3j390kqgxp1hc3mlhdc00000gn/T/tmplhSY8A/extensions/fxdriver@googlecode.com/components/command-processor.js:12534)\n",
      "    at DelayedCommand.prototype.executeInternal_ (file:///var/folders/tq/rz1w3j390kqgxp1hc3mlhdc00000gn/T/tmplhSY8A/extensions/fxdriver@googlecode.com/components/command-processor.js:12539)\n",
      "    at DelayedCommand.prototype.execute/< (file:///var/folders/tq/rz1w3j390kqgxp1hc3mlhdc00000gn/T/tmplhSY8A/extensions/fxdriver@googlecode.com/components/command-processor.js:12481)\n",
      "187\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "while True:\n",
    "    # Get source of current page and create soup\n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src, \"html.parser\")\n",
    "    \n",
    "    # All result links are enclosed in a strong tag; save to list.\n",
    "    for tag in soup.find_all('strong'):\n",
    "        linkbox = tag.find('a')\n",
    "        if linkbox:\n",
    "            links.append(linkbox['href'])\n",
    "    # After all results have beeen saved, use Selenium to go to the next page\n",
    "    try:\n",
    "        nextresults = browser.find_element_by_link_text('Next Page')\n",
    "        nextresults.click()\n",
    "        time.sleep(1)\n",
    "    # Stop when there is no longer a \"Next Page\" link\n",
    "    except Exception, e:\n",
    "        print \"End of results\"\n",
    "        print \"=====================================\"\n",
    "        print e\n",
    "        break\n",
    "\n",
    "# remove duplicates\n",
    "links = list(set(links))\n",
    "print len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the links that we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(links, open(\"../data/mins_links.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "links = pickle.load(open(\"..data/mins_links.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach for obtaining the links cannot be used as easily since Javacript used on the FOMC site makes tag selection difficult. \n",
    "Attempting to find strong results in no urls being found. \n",
    "\n",
    "\n",
    "However, given the links that we found above, we can still use requests to obtain the page contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from requests.exceptions import ConnectionError\n",
    "# Create empty dictionary to store all of the page text we will get\n",
    "fomc_mins_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of links scraped: 183\n",
      "Total number of links available: 187\n"
     ]
    }
   ],
   "source": [
    "# this code block can be run multiple times--we check for duplicates\n",
    "searched_urls = fomc_mins_all.keys()\n",
    "\n",
    "for url in links:\n",
    "    # All HTML meeting minutes end in .htm. Ignore all others (.pdf, etc.)\n",
    "    if url not in searched_urls and url[-3:] == \"htm\":\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            fomc_mins_all[url] = page.text\n",
    "        except ConnectionError as e:\n",
    "            print \"Error ==> \", e, \"for\", date\n",
    "        time.sleep(1)\n",
    "\n",
    "print \"Number of links scraped: %s\" % len(fomc_mins_all.keys())\n",
    "print \"Total number of links available: %s\" % len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store our page sources a dictionary indexed by the FOMC minutes url. We'll clean up by standardizing the format of the keys which encode the date information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "mins_html = open(\"../data/fomc_mins_all.json\", \"wb\")\n",
    "json.dump(fomc_mins_all, mins_html)\n",
    "mins_html.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/fomc_mins_all.json\", \"rb\") as infile:\n",
    "    fomc_mins_all = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fomc_mins_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cleaning keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now clean the keys of the dictionary so that they correspond to the actual dates in standardized form. We want to use the date string at the end of the URL as our actual key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.federalreserve.gov/fomc/MINUTES/1993/19930707min.htm\n",
      "http://www.federalreserve.gov/fomc/minutes/20030129.htm\n"
     ]
    }
   ],
   "source": [
    "# This is what the two types of URLs look like. We edit the key accordingly.\n",
    "print fomc_mins_all.keys()[0]\n",
    "print fomc_mins_all.keys()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "for old_k in fomc_mins_all.keys():\n",
    "    # Construct the new key\n",
    "    if old_k[-5].isdigit():\n",
    "        new_k = old_k[-12:-4]\n",
    "    else:\n",
    "        new_k = old_k[-15:-7]\n",
    "    \n",
    "    # Copy each page into the dictionary with its new key\n",
    "    dates.append(new_k)\n",
    "    fomc_mins_all[new_k] = fomc_mins_all[old_k]\n",
    "    del fomc_mins_all[old_k]\n",
    "\n",
    "# Create orderd list of all pages in the dictionary\n",
    "dates = list(set(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fomc_mins_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "mins_html = open(\"../data/fomc_mins_all.json\", \"wb\")\n",
    "json.dump(fomc_mins_all, mins_html)\n",
    "mins_html.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/fomc_mins_all.json\", \"rb\") as infile:\n",
    "    fomc_mins_all = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Obtaining historical rate changes from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia has a list of FOMC actions along with the associated rate change and other summary information here: https://en.wikipedia.org/wiki/History_of_Federal_Open_Market_Committee_actions. We scrape the table towards the bottom of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultpage = requests.get(\"https://en.wikipedia.org/wiki/History_of_Federal_Open_Market_Committee_actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ressoup = BeautifulSoup(resultpage.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia has color codes to indicate the change (up or down) from the previous rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IGREEN = '#66F500'\n",
    "IBLUE = '#CCEEFF'\n",
    "IRED = '#FFB6B6'\n",
    "IYELLOW = '#FFE153'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use some helping functions to extract the movements and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col2mov(colcode):\n",
    "    if colcode == IGREEN:\n",
    "        movement = 0\n",
    "    elif colcode == IBLUE:\n",
    "        movement = 1\n",
    "    elif colcode == IRED:\n",
    "        movement = True\n",
    "    elif colcode == IYELLOW:\n",
    "        movement = -1\n",
    "    else:\n",
    "        #print \"No color match\"\n",
    "        movement = None\n",
    "    return movement\n",
    "\n",
    "def month2num(date):\n",
    "    return{\n",
    "        'Jan' : 1,\n",
    "        'January': 1,\n",
    "        'Feb' : 2,\n",
    "        'Mar' : 3,\n",
    "        'Apr' : 4,\n",
    "        'May' : 5,\n",
    "        'Jun' : 6,\n",
    "        'Jul' : 7,\n",
    "        'Aug' : 8,\n",
    "        'Sep' : 9,\n",
    "        'September': 9,\n",
    "        'Oct' : 10,\n",
    "        'Nov' : 11,\n",
    "        'November': 11,\n",
    "        'Dec' : 12\n",
    "    }[date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restable = ressoup.find('table', {'class': 'wikitable'}).find_all('tr')\n",
    "\n",
    "actions = {}\n",
    "\n",
    "for row in restable:\n",
    "    entries = row.find_all('td')\n",
    "    \n",
    "    # skip if nothing found\n",
    "    if not entries:\n",
    "        continue\n",
    "    \n",
    "    # extract date information\n",
    "    date = entries[0].contents[0]\n",
    "    datespan = entries[0].find('span')\n",
    "    if datespan:\n",
    "        date = datespan.contents[0]\n",
    "    try:\n",
    "        datecol = entries[0]['style'][-7:]\n",
    "    except KeyError, e:\n",
    "        datecol = None\n",
    "\n",
    "    datels = date.split()\n",
    "    date = datels[2] + \\\n",
    "        str(month2num(datels[0])).zfill(2) + \\\n",
    "        datels[1].strip(',').zfill(2)\n",
    "\n",
    "    # extract federal funds rate info\n",
    "    ffr = entries[1].contents[0][:-1]\n",
    "    ffrcol = entries[1]['style'][-7:]\n",
    "\n",
    "    # extract discount rate info\n",
    "    discr = float(entries[2].contents[0][:-1])\n",
    "    discrcol = entries[2]['style'][-7:]\n",
    "\n",
    "    # match color codes for rate movement info\n",
    "    special = col2mov(datecol)\n",
    "    ffrmov = col2mov(ffrcol)\n",
    "    discrmov = col2mov(discrcol)\n",
    "\n",
    "    # store information in dictionary with dates as keys\n",
    "    actions[date] = [special, ffr, ffrmov, discr, discrmov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save our data in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fomc_actions = open(\"../data/actions_05-15.json\", \"wb\")\n",
    "json.dump(actions, fomc_actions)\n",
    "fomc_actions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/actions_05-15.json\", \"rb\") as infile:\n",
    "    actions = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Please go to the next notebook, `sentiment_analysis.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
