{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping a wider range of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyquery import PyQuery as pq\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fedurl_base = \"http://search.newyorkfed.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Selenium WebDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first used Selenium to obtain all the links of the FOMC minutes on the FOMC website.\n",
    "\n",
    "Selenium offers an advantage over basic requests--it doesn't run into php/javacript tag selector issues because it simulates an actual human browsing the website. (The search engine from which the links are obtained uses a php/javascript backend.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize browser\n",
    "# Use Ctrl+Enter (don't use Shift+Enter)\n",
    "browser = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium allows us to go directly to the search page with text already in the input query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "browser.get(\"http://search.newyorkfed.org/fomc-docs/search?advanced_search=true&fomc_document_type=minutes&text=.htm&search_precision=All+Words&from_month=3&from_year=1936&to_month=12&to_year=2015&sort=Most+Recent+First&Search=Search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through each page of the search results and collect all the links by storing them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of results\n",
      "=====================================\n",
      "Message: Unable to locate element: {\"method\":\"link text\",\"selector\":\"Next Page\"}\n",
      "Stacktrace:\n",
      "    at FirefoxDriver.prototype.findElementInternal_ (file:///c:/users/george/appdata/local/temp/tmpvkqyi5/extensions/fxdriver@googlecode.com/components/driver-component.js:10659)\n",
      "    at FirefoxDriver.prototype.findElement (file:///c:/users/george/appdata/local/temp/tmpvkqyi5/extensions/fxdriver@googlecode.com/components/driver-component.js:10668)\n",
      "    at DelayedCommand.prototype.executeInternal_/h (file:///c:/users/george/appdata/local/temp/tmpvkqyi5/extensions/fxdriver@googlecode.com/components/command-processor.js:12534)\n",
      "    at DelayedCommand.prototype.executeInternal_ (file:///c:/users/george/appdata/local/temp/tmpvkqyi5/extensions/fxdriver@googlecode.com/components/command-processor.js:12539)\n",
      "    at DelayedCommand.prototype.execute/< (file:///c:/users/george/appdata/local/temp/tmpvkqyi5/extensions/fxdriver@googlecode.com/components/command-processor.js:12481)\n",
      "187\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "while True:\n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src, \"html.parser\")\n",
    "    \n",
    "    for tag in soup.find_all('strong'):\n",
    "        linkbox = tag.find('a')\n",
    "        if linkbox:\n",
    "            links.append(linkbox['href'])\n",
    "    try:\n",
    "        nextresults = browser.find_element_by_link_text('Next Page')\n",
    "        nextresults.click()\n",
    "        time.sleep(1)\n",
    "    except Exception, e:\n",
    "        print \"End of results\"\n",
    "        print \"=====================================\"\n",
    "        print e\n",
    "        break\n",
    "\n",
    "# remove duplicates\n",
    "links = list(set(links))\n",
    "print len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the links that we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(links, open(\"mins_links.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "links = pickle.load(open(\"mins_links.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach for obtaining the links cannot be used as easily since Javacript used on the FOMC site makes tag selection difficult. \n",
    "Attempting to find strong results in no urls being found. \n",
    "\n",
    "\n",
    "However, given the links that we found above, we can still use requests to obtain the page contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "fomc_mins_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished getting page sources\n"
     ]
    }
   ],
   "source": [
    "# this code block can be run multiple times--we check for duplicates\n",
    "searched_urls = fomc_mins_all.keys()\n",
    "\n",
    "for url in links:\n",
    "    if url not in searched_urls and url[-3:] == \"htm\":\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            fomc_mins_all[url] = page.text\n",
    "        except ConnectionError as e:\n",
    "            print \"Error ==> \", e, \"for\", date\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "print \"Finished getting page sources\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store our page sources a dictionary indexed by the FOMC minutes url. We'll clean up by standardizing the format of the keys which encode the date information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "mins_html = open(\"fomc_mins_all.json\", \"wb\")\n",
    "json.dump(fomc_mins_all, mins_html)\n",
    "mins_html.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"fomc_mins_all.json\", \"rb\") as infile:\n",
    "    fomc_mins_all = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fomc_mins_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cleaning keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now clean the keys of the dictionary so that they correspond to the actual dates in standardized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "for old_k in fomc_mins_all.keys():\n",
    "    if old_k[-5].isdigit():\n",
    "        new_k = old_k[-12:-4]\n",
    "    else:\n",
    "        new_k = old_k[-15:-7]\n",
    "    \n",
    "    dates.append(new_k)\n",
    "    fomc_mins_all[new_k] = fomc_mins_all[old_k]\n",
    "    del fomc_mins_all[old_k]\n",
    "\n",
    "dates = list(set(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fomc_mins_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "mins_html = open(\"fomc_mins_all.json\", \"wb\")\n",
    "json.dump(fomc_mins_all, mins_html)\n",
    "mins_html.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"fomc_mins_all.json\", \"rb\") as infile:\n",
    "    fomc_mins_all = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Obtaining historical rate changes from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia has a list of FOMC actions along with the associated rate change and other summary information here: https://en.wikipedia.org/wiki/History_of_Federal_Open_Market_Committee_actions. We scrape the table towards the bottom of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultpage = requests.get(\"https://en.wikipedia.org/wiki/History_of_Federal_Open_Market_Committee_actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ressoup = BeautifulSoup(resultpage.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia has color codes to indicate the change (up or down) from the previous rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IGREEN = '#66F500'\n",
    "IBLUE = '#CCEEFF'\n",
    "IRED = '#FFB6B6'\n",
    "IYELLOW = '#FFE153'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use some helping functions to extract the movements and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col2mov(colcode):\n",
    "    if colcode == IGREEN:\n",
    "        movement = 0\n",
    "    elif colcode == IBLUE:\n",
    "        movement = 1\n",
    "    elif colcode == IRED:\n",
    "        movement = True\n",
    "    elif colcode == IYELLOW:\n",
    "        movement = -1\n",
    "    else:\n",
    "        #print \"No color match\"\n",
    "        movement = None\n",
    "    return movement\n",
    "\n",
    "def month2num(date):\n",
    "    return{\n",
    "        'Jan' : 1,\n",
    "        'January': 1,\n",
    "        'Feb' : 2,\n",
    "        'Mar' : 3,\n",
    "        'Apr' : 4,\n",
    "        'May' : 5,\n",
    "        'Jun' : 6,\n",
    "        'Jul' : 7,\n",
    "        'Aug' : 8,\n",
    "        'Sep' : 9,\n",
    "        'September': 9,\n",
    "        'Oct' : 10,\n",
    "        'Nov' : 11,\n",
    "        'November': 11,\n",
    "        'Dec' : 12\n",
    "    }[date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restable = ressoup.find('table', {'class': 'wikitable'}).find_all('tr')\n",
    "\n",
    "actions = {}\n",
    "\n",
    "for row in restable:\n",
    "    entries = row.find_all('td')\n",
    "    \n",
    "    # skip if nothing found\n",
    "    if not entries:\n",
    "        continue\n",
    "    \n",
    "    # extract date information\n",
    "    date = entries[0].contents[0]\n",
    "    datespan = entries[0].find('span')\n",
    "    if datespan:\n",
    "        date = datespan.contents[0]\n",
    "    try:\n",
    "        datecol = entries[0]['style'][-7:]\n",
    "    except KeyError, e:\n",
    "        datecol = None\n",
    "\n",
    "    datels = date.split()\n",
    "    date = datels[2] + \\\n",
    "        str(month2num(datels[0])).zfill(2) + \\\n",
    "        datels[1].strip(',').zfill(2)\n",
    "\n",
    "    # extract federal funds rate info\n",
    "    ffr = entries[1].contents[0][:-1]\n",
    "    ffrcol = entries[1]['style'][-7:]\n",
    "\n",
    "    # extract discount rate info\n",
    "    discr = float(entries[2].contents[0][:-1])\n",
    "    discrcol = entries[2]['style'][-7:]\n",
    "\n",
    "    # match color codes for rate movement info\n",
    "    special = col2mov(datecol)\n",
    "    ffrmov = col2mov(ffrcol)\n",
    "    discrmov = col2mov(discrcol)\n",
    "\n",
    "    # store information in dictionary with dates as keys\n",
    "    actions[date] = [special, ffr, ffrmov, discr, discrmov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save our data in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fomc_actions = open(\"actions_05-15.json\", \"wb\")\n",
    "json.dump(actions, fomc_actions)\n",
    "fomc_actions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"actions_05-15.json\", \"rb\") as infile:\n",
    "    action = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
