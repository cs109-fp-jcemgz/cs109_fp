{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pyquery import PyQuery as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "We begin by parsing the text and pre-processing it to prepare it for Latent Dirichlet Analysis. This step is meant to remove stopwords and identify nouns and adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list('.,;:!?()[]{}`''\\\"@#$^&*+-|=~_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "stopwords=text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FOMC statements are full of phrases like \"growth is expected to continue--given the current data--at a moderate pace\". The two hyphens should be treated as a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex1=re.compile(r\"\\-{2,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function to find the nouns and adjectives of the text. The function returns a tuple where the first element is a list of lists, where each list includes the nouns from a sentence. The second element is a list of lists, where each list includes the adjectives from a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modified_get_parts(thetext):\n",
    "    thetext=re.sub(regex1, ', ', thetext)\n",
    "    nouns=[]\n",
    "    descriptives=[]\n",
    "    for i,sentence in enumerate(parse(thetext, tokenize=True, lemmata=True).split()):\n",
    "        \n",
    "        # Skip the first three sentences that include the HTML\n",
    "        nouns.append([])\n",
    "        descriptives.append([])\n",
    "#         if i in range(1,4):\n",
    "#             continue\n",
    "            \n",
    "        for token in sentence:\n",
    "            #print token\n",
    "            if len(token[4]) >0:\n",
    "                if token[1] in ['JJ', 'JJR', 'JJS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "            \n",
    "                    descriptives[i].append(token[4])\n",
    "                elif token[1] in ['NN', 'NNS']:\n",
    "                    if token[4] in stopwords or token[4][0] in punctuation or token[4][-1] in punctuation or len(token[4])==1:\n",
    "                        continue\n",
    "                    nouns[i].append(token[4])\n",
    "    out=zip(nouns, descriptives)\n",
    "    nouns2=[]\n",
    "    descriptives2=[]\n",
    "    for n,d in out:\n",
    "        if len(n)!=0 and len(d)!=0:\n",
    "            nouns2.append(n)\n",
    "            descriptives2.append(d)\n",
    "    return nouns2[1:], descriptives2[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in the fomc_mins_all dictionary that we created in the Scraping.ipynb iPython Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"fomc_mins_all.json\", \"rb\") as infile:\n",
    "    fomc_mins = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check how our modified_get_parts function would deal with a sample FOMC statement, printing out the first two noun lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'buildmenu',\n",
       "  u'policy',\n",
       "  u'minute',\n",
       "  u'meeting',\n",
       "  u'office',\n",
       "  u'governor',\n",
       "  u'present',\n",
       "  u'member',\n",
       "  u'president',\n",
       "  u'economist',\n",
       "  u'dev'],\n",
       " [u'governor',\n",
       "  u'governor',\n",
       "  u'adviser',\n",
       "  u'governor',\n",
       "  u'governor',\n",
       "  u'governor',\n",
       "  u'merten',\n",
       "  u'interval',\n",
       "  u'meeting',\n",
       "  u'subcommittee',\n",
       "  u'communication',\n",
       "  u'issue']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_get_parts(pq(fomc_mins['20140730']).text())[0][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run modified_get_parts on each fomc statement and create a new dictionary fomc_parts. We strip each statement of the html at its start before passing it to modified_get_parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fomc_parts = {}\n",
    "for key in fomc_mins.keys():\n",
    "    fomc_parts[key] = modified_get_parts(pq(fomc_mins[key]).text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fomc_parts_file = open(\"fomc_parts.json\", \"wb\")\n",
    "json.dump(fomc_parts, fomc_parts_file)\n",
    "fomc_parts_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create two lists, a list of nouns for each sentence, and a flattened list of all the nouns which we will create to produce a dictionary (needed as an argument for the LDA function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nvocab = []\n",
    "for key in fomc_mins.keys():\n",
    "    nouns = fomc_parts[key][0]\n",
    "    for nounlist in nouns:\n",
    "        nvocab.append(nounlist)\n",
    "\n",
    "flattenednvocab = []\n",
    "for key in fomc_mins.keys():\n",
    "    nouns = fomc_parts[key][0]\n",
    "    for nounlist in nouns:\n",
    "        for n in nounlist:\n",
    "            flattenednvocab.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "frequency = Counter(flattenednvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id2word = {}; vocab = {}\n",
    "for i,word in enumerate(frequency.keys()):\n",
    "    vocab[word] = i \n",
    "    id2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2759"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def sentencelist(sentence):\n",
    "    d = defaultdict(int); group = []\n",
    "    for word in sentence:\n",
    "        word_id = vocab[word] \n",
    "        d[word_id] += 1 \n",
    "    group = [(a, d[a]) for a in d.keys()]\n",
    "    return group\n",
    "corpus = [sentencelist(sentence) for sentence in nvocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda2 = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word = id2word, update_every=1, chunksize=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.043*inflation + 0.037*policy + 0.035*market + 0.035*rate + 0.023*member + 0.022*participant + 0.019*meeting + 0.019*period + 0.018*condition + 0.018*fund',\n",
       " u'0.039*price + 0.022*quarter + 0.021*labor + 0.021*increase + 0.019*growth + 0.019*consumer + 0.019*month + 0.017*business + 0.016*spending + 0.016*activity']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Approach: Training a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the vocabulary of adjectives that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened_adj_vocab = []\n",
    "for key in fomc_mins.keys():\n",
    "    nouns = fomc_parts[key][1]\n",
    "    for nounlist in nouns:\n",
    "        for n in nounlist:\n",
    "            flattened_adj_vocab.append(n)\n",
    "\n",
    "frequency2 = Counter(flattened_adj_vocab)\n",
    "id2adj = {}; adjvocab = {}\n",
    "for i,word in enumerate(frequency2.keys()):\n",
    "    adjvocab[word] = i \n",
    "    id2adj[i] = word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine the adjectives in each statement into a single list and thereby have a list of adjectives for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjvocab = []\n",
    "for key in fomc_mins.keys():\n",
    "    nouns = fomc_parts[key][1]\n",
    "    for nounlist in nouns:\n",
    "        adjvocab.append(nounlist)\n",
    "X = adjvocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Response Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"actions_05-15.json\", \"rb\") as infile:\n",
    "    decisions = json.load(infile)\n",
    "len(decisions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decisions_work = decisions.copy()\n",
    "new_decisions = {}\n",
    "for key in fomc_mins:\n",
    "    if key in decisions_work.keys():\n",
    "        new_decisions[key] = decisions_work[key][-1]\n",
    "        del decisions_work[key]\n",
    "        \n",
    "len(new_decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 182 statements and 52 decisions. Of the 52 decisions, 47 are found in the 182 statements, 5 are not.\n",
    "\n",
    "TODO:\n",
    "- Assign the 5 that are not to the fomc statement immediately preceding them\n",
    "- Work out how we will deal with the mismatch in dimensions -> 182 x 52. Will we collapse  the 182 into groups? But that would reduce the data points available to us given that they are already few. Maybe find more points for the 130 points that remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(len(X)), train_size=0.7)\n",
    "mask=np.ones(len(X), dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_xy(X_col, y_col, vectorizer):\n",
    "    X = vectorizer.fit_transform(X_col)\n",
    "    y = y_col\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "log_likelihood\n",
    "\n",
    "Compute the log likelihood of a dataset according to \n",
    "a Naive Bayes classifier. \n",
    "The Log Likelihood is defined by\n",
    "\n",
    "L = Sum_positive(logP(positive)) + Sum_negative(logP(negative))\n",
    "\n",
    "Where Sum_positive indicates a sum over all positive reviews, \n",
    "and Sum_negative indicates a sum over negative reviews\n",
    "    \n",
    "Parameters\n",
    "----------\n",
    "clf : Naive Bayes classifier\n",
    "x : (nexample, nfeature) array\n",
    "    The input data\n",
    "y : (nexample) integer array\n",
    "    Whether each review is Fresh\n",
    "\"\"\"\n",
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    rotten = y == 0\n",
    "    fresh = ~rotten\n",
    "    return prob[rotten,0].sum() + prob[fresh,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def cv_score(clf, x, y, score_func, nfold=5):\n",
    "    \"\"\"\n",
    "    Uses 5-fold cross validation to estimate a score of a classifier\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    clf : Classifier object\n",
    "    x : Input feature vector\n",
    "    y : Input class labels\n",
    "    score_func : Function like log_likelihood, that takes (clf, x, y) as input,\n",
    "                 and returns a score\n",
    "                 \n",
    "    Returns\n",
    "    -------\n",
    "    The average score obtained by splitting (x, y) into 5 folds of training and \n",
    "    test sets, fitting on the training set, and evaluating score_func on the test set\n",
    "    \n",
    "    Examples\n",
    "    cv_score(clf, x, y, log_likelihood)\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf, x[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibration_plot(clf, xtest, ytest):\n",
    "    prob = clf.predict_proba(xtest)[:, 1]\n",
    "    outcome = ytest\n",
    "    data = pd.DataFrame(dict(prob=prob, outcome=outcome))\n",
    "\n",
    "    #group outcomes into bins of similar probability\n",
    "    bins = np.linspace(0, 1, 20)\n",
    "    cuts = pd.cut(prob, bins)\n",
    "    binwidth = bins[1] - bins[0]\n",
    "    \n",
    "    #freshness ratio and number of examples in each bin\n",
    "    cal = data.groupby(cuts).outcome.agg(['mean', 'count'])\n",
    "    cal['pmid'] = (bins[:-1] + bins[1:]) / 2\n",
    "    cal['sig'] = np.sqrt(cal.pmid * (1 - cal.pmid) / cal['count'])\n",
    "        \n",
    "    #the calibration plot\n",
    "    ax = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    p = plt.errorbar(cal.pmid, cal['mean'], cal['sig'])\n",
    "    plt.plot(cal.pmid, cal.pmid, linestyle='--', lw=1, color='k')\n",
    "    plt.ylabel(\"Empirical P(+)\")\n",
    "    \n",
    "    #the distribution of P(+)\n",
    "    ax = plt.subplot2grid((3, 1), (2, 0), sharex=ax)\n",
    "    \n",
    "    plt.bar(left=cal.pmid - binwidth / 2, height=cal['count'],\n",
    "            width=.95 * (bins[1] - bins[0]),\n",
    "            fc=p[0].get_color())\n",
    "    \n",
    "    plt.xlabel(\"Predicted P(+)\")\n",
    "    plt.ylabel(\"Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"alpha: %f\" % best_alpha\n",
    "print \"min_df: %f\" % best_min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=adjvocab, min_df=best_min_df)\n",
    "Xnew, ynew = make_xy(X, y, vectorizer)\n",
    "xtrain=Xnew[mask]\n",
    "ytrain=ynew[mask]\n",
    "xtest=Xnew[~mask]\n",
    "ytest=ynew[~mask]\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
    "\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print \"Accuracy on training data: %0.4f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.4f\" % (test_accuracy)\n",
    "\n",
    "calibration_plot(clf, xtest, np.ravel(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most important features according to our classifier? The visualization belows shows the top 10 features in terms of their log probabilities for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can add bar chart x-axis features (adjectives), y-axis probs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the visualization. Is it what we thouht it would be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Approach: Using the Loughran-McDonald Financial Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first approach assigned probabilities to words based on the training set of FOMC statements we have. However, the success of this is limited by the number of FOMC statements (182) that we have access to. We can improve this analysis by using more accurate probabilities given by a dictionary that focuses on finance. The **Loughran-McDonald 2014 Master Dictionary** is a great tool for our purposes as it includes words that often appear in 10-K documents and other financial statements. The dictionary includes 9 sentiment categories, including \"negative\", \"positive\", \"uncertainty\", \"litigious\", \"modal\", and \"constraining\", among others. The categories given by this dictionary are more useful to us because of the sheer size of the data set used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the data. Below is an example of the data encapsulated in $lmdf$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "      <th>Irr_Verb</th>\n",
       "      <th>Harvard_IV</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENCUMBER</td>\n",
       "      <td>24454</td>\n",
       "      <td>87222</td>\n",
       "      <td>6.130000e-06</td>\n",
       "      <td>2.570000e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>44863</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENCUMBERED</td>\n",
       "      <td>24455</td>\n",
       "      <td>86996</td>\n",
       "      <td>6.110000e-06</td>\n",
       "      <td>3.480000e-06</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>44409</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENCUMBERING</td>\n",
       "      <td>24456</td>\n",
       "      <td>51445</td>\n",
       "      <td>3.610000e-06</td>\n",
       "      <td>3.660000e-06</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>19907</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENCUMBERS</td>\n",
       "      <td>24457</td>\n",
       "      <td>4835</td>\n",
       "      <td>3.400000e-07</td>\n",
       "      <td>1.380000e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3258</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENCUMBRANCE</td>\n",
       "      <td>24458</td>\n",
       "      <td>223181</td>\n",
       "      <td>1.570000e-05</td>\n",
       "      <td>6.260000e-06</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>72129</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Sequence Number  Word Count  Word Proportion  \\\n",
       "0     ENCUMBER            24454       87222     6.130000e-06   \n",
       "1   ENCUMBERED            24455       86996     6.110000e-06   \n",
       "2  ENCUMBERING            24456       51445     3.610000e-06   \n",
       "3    ENCUMBERS            24457        4835     3.400000e-07   \n",
       "4  ENCUMBRANCE            24458      223181     1.570000e-05   \n",
       "\n",
       "   Average Proportion   Std Dev  Doc Count  Negative  Positive  Uncertainty  \\\n",
       "0        2.570000e-06  0.000017      44863      2009         0            0   \n",
       "1        3.480000e-06  0.000028      44409      2009         0            0   \n",
       "2        3.660000e-06  0.000050      19907      2009         0            0   \n",
       "3        1.380000e-07  0.000004       3258      2009         0            0   \n",
       "4        6.260000e-06  0.000036      72129      2009         0            0   \n",
       "\n",
       "   Litigious  Constraining  Superfluous  Interesting  Modal  Irr_Verb  \\\n",
       "0       2009          2009            0            0      0         0   \n",
       "1       2009          2009            0            0      0         0   \n",
       "2       2009          2009            0            0      0         0   \n",
       "3       2009          2009            0            0      0         0   \n",
       "4       2009          2009            0            0      0         0   \n",
       "\n",
       "   Harvard_IV  Syllables     Source  \n",
       "0           0          3  12of12inf  \n",
       "1           0          3  12of12inf  \n",
       "2           0          4  12of12inf  \n",
       "3           0          3  12of12inf  \n",
       "4           0          3  12of12inf  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmdf = pd.read_csv(\"shortMcDonaldDictionary.csv\")\n",
    "lmdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lmdf = lmdf[[\"Word\",\"Negative\",\"Positive\",\"Uncertainty\",\"Litigious\",\"Constraining\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENCUMBER</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENCUMBERED</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENCUMBERING</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENCUMBERS</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENCUMBRANCE</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Negative  Positive  Uncertainty  Litigious  Constraining\n",
       "0     ENCUMBER      2009         0            0       2009          2009\n",
       "1   ENCUMBERED      2009         0            0       2009          2009\n",
       "2  ENCUMBERING      2009         0            0       2009          2009\n",
       "3    ENCUMBERS      2009         0            0       2009          2009\n",
       "4  ENCUMBRANCE      2009         0            0       2009          2009"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary includes 9 sentiment categories (e.g. \"negative\", \"positive\", \"uncertainty\", \"litigious\", \"modal\", and \"constraining\"). We reduce the dimensionality of this data down to just three categories: \"negative\", \"positive\", and \"uncertain\". A $word$ that is \"uncertain\" is assigned the probabilities $$P(word_u\\,|\\,-)=P(word_u\\,|\\,+)=\\frac{1}{2}$$\n",
    "We set words in the \"positive\" and \"negative\" parts to have 90% probabilities of being in the group they are assigned to (based on the average probability given by Loughran and McDonald).\n",
    "$$P(word_p\\,|\\,+) = 0.9, P(word_p\\,|\\,-) = 0.1$$\n",
    "$$P(word_n\\,|\\,-) = 0.1, P(word_n\\,|\\,-) = 0.9$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adjust $lmdf$ to reflect these decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Positive Prob</th>\n",
       "      <th>Negative Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENCUMBER</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENCUMBERED</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENCUMBERING</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENCUMBERS</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENCUMBRANCE</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Positive Prob  Negative Prob\n",
       "0     ENCUMBER            0.1            0.9\n",
       "1   ENCUMBERED            0.1            0.9\n",
       "2  ENCUMBERING            0.1            0.9\n",
       "3    ENCUMBERS            0.1            0.9\n",
       "4  ENCUMBRANCE            0.1            0.9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmdf_adjusted = lmdf.copy(deep=True)\n",
    "N = 0; P = 0\n",
    "new_values = [0 for i in range(len(lmdf_adjusted.values))]\n",
    "for i, r in enumerate(lmdf_adjusted.values):\n",
    "    if r[1] > 0 or r[4] > 0 or r[5] > 0:\n",
    "        N = 0.9; P = 0.1\n",
    "    elif r[2] > 0:\n",
    "        N = 0.1; P = 0.9\n",
    "    elif r[3] > 0:\n",
    "        N = 0.5; P = 0.5\n",
    "    new_values[i] = [r[0], P, N]\n",
    "\n",
    "final_lmdf = pd.DataFrame(new_values, index=lmdf_adjusted.index, columns = [\"Word\", \"Positive Prob\", \"Negative Prob\"])\n",
    "final_lmdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to calculate the probability of a sentence being positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_probs = {}\n",
    "for row in final_lmdf.values:\n",
    "    dict_probs[row[0]] = [row[1], row[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We modify calc_pplus to incorporate our new found knowledge. We now check if a word is in the financial dictionary first.\n",
    "If it is then we use that probabilty, otherwise we use the probability from our earlier Naive Bayes classifier.\n",
    "\n",
    "We also multiply the probabilities from the financial dictionary by a factor to emphasize their importance (based on the\n",
    "fact that we are more confident in their values).\n",
    "\"\"\"\n",
    "\n",
    "def modified_calc_pplus(adjlist, dict_probs, lp, ln, pp, pn):\n",
    "    FACTOR = 1\n",
    "    \n",
    "    prob_p = 0; prob_n = 0\n",
    "    for adj in adjlist:\n",
    "        # Check if the adjective is in the financial dictionary\n",
    "        # If it is take, probability from there\n",
    "        if adj in dict_probs.keys():\n",
    "            prob_p += FACTOR * dict_probs[adj][0]\n",
    "            prob_n += FACTOR * dict_probs[adj][1]\n",
    "        else:    \n",
    "            prob_p += lp[adj]\n",
    "            prob_n += ln[adj]\n",
    "    prob_pos = prob_p * pp\n",
    "    prob_neg = prob_n * pn\n",
    "    prob = float(prob_pos)/(prob_pos + prob_neg)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential commentary: We can find the most \"positive\" and most \"negative\" sentences and comment on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential commentary: Regression of length of text against positive or negative. Interesting to do given the Fed's policy of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Directional Policy\": Federal Reserve Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Federal Reserve has claimed at several points in the past decade that it attempts to affect financial markets (especially post-crisis) through the release of increasingly long statements that help outline and bring about the changes it hopes for. We take this as a launch pad for another potential statistical analysis that may turn out to be useful for our work. We examine the relationship between the length of statements and their outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm, ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_ols_model = ols('Y ~ Length', length_data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length_ols_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some comment on the R^2 value of our data goes here. General comment about whether or not there is a relati"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
